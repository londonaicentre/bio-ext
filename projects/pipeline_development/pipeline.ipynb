{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from mlflow.models import infer_signature\n",
    "from bioext.doccano_utils import DoccanoSession\n",
    "from bioext.hfpipeline import GlobalConfig, DataSource, TaskType, DataHandler, HFSequenceClassificationTrainer\n",
    "from transformers import AutoTokenizer\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is for testing the functionality of hfpipeline.py\n",
    "# Before using, load up your local Doccano instance and create a project + load data\n",
    "# Sample pre-labelled data is provided in ./imports for binary classification, multiclass (3 label) classification, and multilabel (4 label) classification\n",
    "# A pre-labelled NER dataset is provided, but not yet implemented in hfpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "docsesh = DoccanoSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = docsesh.client.list_projects()\n",
    "\n",
    "for project in projects:\n",
    "    print(f\"Project ID: {project.id}, Name: {project.name}, Type: {project.project_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GlobalConfig(\n",
    "    doc_project_id=1,\n",
    "    source=DataSource.DOCCANO,\n",
    "    task=TaskType.MULTILABEL,\n",
    "    num_labels=4,\n",
    "    model_name=\"distilbert-base-uncased\",\n",
    "    max_length=256,\n",
    "    batch_size=16,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=3,\n",
    "    output_dir=\"./model_output\"\n",
    ")\n",
    "\n",
    "# data handler to load and preprocess data\n",
    "data_handler = DataHandler(config=config)\n",
    "\n",
    "print(f\"Training samples: {len(data_handler.train_dataset)}\")\n",
    "print(f\"Testing samples: {len(data_handler.test_dataset)}\")\n",
    "\n",
    "sample = data_handler.train_dataset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise trainer\n",
    "trainer = HFSequenceClassificationTrainer(\n",
    "    config=config,\n",
    "    tokenizer=data_handler.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.setup_trainer(\n",
    "    train_dataset=data_handler.train_dataset,\n",
    "    eval_dataset=data_handler.test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up Experiment on MLflow\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"bert-binary-classification\"\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "# mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(\"Set up Experiment on MLflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.520203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.499661</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493799</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/01 12:33:29 WARNING mlflow.models.signature: Failed to infer schema for inputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. Note that MLflow doesn't validate data types during inference for AnyType. To see the full traceback, set logging level to DEBUG.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log training params\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527e333e14ee441cb98ccf78c4d38354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31a58702dfb468c9a93ff473d40dcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/11.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics\n",
      "Evaluation metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run blushing-cod-734 at: http://localhost:5001/#/experiments/1/runs/3f32033803b94ec0b27965880d00fe6d\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n",
      "Model saved to: /Users/sratkai/Documents/projects/bio-ext/projects/pipeline_development/model_output\n",
      "Training metrics:\n",
      "train_runtime: 7.81\n",
      "train_samples_per_second: 19.21\n",
      "train_steps_per_second: 1.54\n",
      "total_flos: 9935409254400.00\n",
      "train_loss: 0.52\n",
      "epoch: 3.00\n",
      "Evaluation metrics:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluation metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43meval_results\u001b[49m.items():\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)):\n\u001b[32m     35\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'eval_results' is not defined"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    training_metrics = trainer.train()\n",
    "    \n",
    "    # log model to mlflow\n",
    "    print(\"Log training params\")\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model={\n",
    "            \"model\": trainer.model,\n",
    "            \"tokenizer\": trainer.tokenizer,\n",
    "        },\n",
    "        artifact_path=\"bert_model\",\n",
    "        task=\"text-classification\",\n",
    "        signature=infer_signature(sample, np.array([[0.1, 0.9]])),\n",
    "    )\n",
    "    \n",
    "    # log metrics to mlflow\n",
    "    print(\"Training metrics\")\n",
    "    mlflow.log_metrics(training_metrics)\n",
    "    \n",
    "    # log metrics to mlflow\n",
    "    print(\"Evaluation metrics\")\n",
    "    eval_metrics = trainer.trainer.evaluate()\n",
    "    mlflow.log_metrics(eval_metrics)\n",
    "\n",
    "\n",
    "print(f\"Model saved to: {os.path.abspath(config.output_dir)}\")\n",
    "print(\"Training metrics:\")\n",
    "for key, value in training_metrics.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "\n",
    "print(\"Evaluation metrics:\")\n",
    "for key, value in eval_metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"{key}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
